为什么要压缩：占据的空间太大

为什么图像和视频可以压缩？
1、也许图像只用了4种颜色，那就不需要每个点都用8bit来保存
2、一个连续区域有大量的像素点都是一个值，那么就可以压缩表示
3、就算有的地方并不严格等于它，但近似成它也没有关系（有损）

压缩的统一标准
图像的压缩算法：JPEG等
视频的压缩算法：H.263，MPEG等
encoder：mapper，quantier，symbol encoder
decoder：反过来
全过程：
原图像 -> 映射 -> 量化 -> 符号编码 -> 存储/传输 -> 符号解码 -> 反映射 -> 图像
0、在映射之前可能还有一环，就是先把图像分块
然后各自独立处理。JPEG是分成8*8的小块

1、映射(Mapper)：对原图像进行变换，使之更容易被压缩。
比如傅里叶变换、小波变换、JPEG的离散余弦变换（DCT）、主成分分析。

2、量化(Quantizer)：量化是压缩的主要图像，主要也是它引入误差的。
一般是整数除法取整，这样比较简便，也比较有效
比如有一个以2为单位的量化器，看到原图像值是17，将它除2向下取整，量化得到8；
图像还原的时候，用8×2=16得到还原值，与真实值相差了1。
这是有损压缩，要对图像的误差进行量度：MSE（均方误差），差-方-和-商-开方

3、符号编码(Symbol encoder)：可以进一步地压缩文件大小。
1）比如，压缩前：第1个点灰色，第2个点灰色，第3个点灰色，第4个点灰色，第5个点灰色，第6个点灰色......第89个点灰色，第90个点黑色......可以记做：第1到89个点灰色，第90个点黑色。
这就是run-length coding，游程编码
2）还比如JPEG使用的哈夫曼(Huffman)编码。它是可变长的：variable-length coding
不同灰度级的像素点出现的次数不一样多。这从histeq上就能看出来。
将重复出现次数多的数据，用简短的符号进行编码；出现次数少的数据，用较长的符号进行编码

另外，以上说的是单通道的图像。
如果是多通道（RGB之类的），还有其他的冗余可以节省下来

Haffman编码：无前缀编码，没有一个编码是另一个的前缀
于是不需要在像素之间设置分隔符，跟着Haffman树走、走到叶节点就结束，就能把它们分开
假如有4个灰度级，频率分别是A=0.25 B=0.47 C=0.25 D=0.03
B		A		C		D
0.47 	0.25	0.25	0.03
B		C+D		A
0.47 	0.28	0.25
(C+D)+A	B
0.53	0.47
((C+D)+A)+B
1
			X
			/\
		X		B=1
		/\
	X		A=01
	/\	
C=000	D=001
现在要使用的编码长度：0.25*2+0.47*1+0.25*3+0.03*3=1.81bit
原来每个像素要8bit；就算量化到每个像素2bit，也比1.81大

Haffman树的最优性：有定理可以证明
Haffman编码是最优的编码方法吗？
熵（信息量）的定义：H = -∑pilog(pi)（以2为底）
-(0.25log0.25+0.47log0.47+0.25log0.25+0.03log0.03) = 1.6637
根据香农第一定理，这就是理想编码的平均长度（下界），Haffman已经很接近了
当然，这是无失真编码的下界

对于RGB图像，JPEG先把它转成YCbCr制式。亮度 + 色彩 + 色彩
这是一个线性变换（矩阵乘法）
然后，图像分块，然后各自独立处理。JPEG是分成8*8的小块
1、本来要做的是K-L变换：有点类似于PCA
都是正交变换，保证变换到的基底是正交的，互相独立
提取出的也是一个特征值矩阵，然后只保留其中的部分大的特征值
对于8*8的小块，只保留一个特征值就够了。保证造成的均方误差是最小的！
但是，效率不高：变换需要用到图像的具体值，所以需要先拿到模版再进行计算
不是只根据位置值，从而能提前把模版算好
2、实际用的是离散余弦变换（DCT），这是一个次优的方案
但是更快。公式略，基本就是傅立叶变换的实部

傅立叶把空间的基变成了很多正弦波
而离散余弦变换把空间的基变成了这个样子（见图）
重申，傅立叶和离散余弦变换的基都是不变的，K-L是变化的
对得到的图像可以只保留左上角（u=0，v=0）的低频部分，就够了；
u和v比较大的基是图像突变的高频部分。然后逆变换
但是JPEG其实没有这么做，大概是损失太大了？
只是这样做的话，高频部分大多接近0，量化后是0
这样可以造成非均匀分布，使用haffman

为什么使用离散余弦变换，而不是傅立叶、哈达玛变换？
因为是近似（？）K-L的最优解

像素之间的依赖性只有临近的像素：一阶马尔可夫图像源？？？
傅立叶的本质还是在假设，图像是周期性的（尽管周期无穷大）
而离散余弦变换是在假设，图像在下一个周期是会与这个周期对称的（见图）
也就是说，在图像边界处是连续的！而不是间断的。这样更好

为什么要分块？做多个小变换比一个大变换更划算
但是，大块也有好处：相邻的像素点之间的相关性都能够保持下来
比如分成2*2的块太小了，每一个块都会被同化成一个值，块之间的差别又较大，块效应很明显
8*8的效果算够好了

另外，一个连续区域有大量的像素点都是一个值，那么就可以压缩表示
所以，按照ZIGZAG的方式来存放所有的像素点。这样类似于二维地对图像进行遍历
如果右下角有很多0，那么它们能集中在一起，而不是在最后几行的末尾离散地出现
于是，JPEG可以用一个提前结束的信号，来节省对很多0的存储

量化
量化主要并不是为了少用一两个bit位进行表示，而是为了做符号编码
比如haffman编码，需要各个保留下来的灰度级进行聚合，造成非均匀分布
注意，8*8的块里面，每一个像素点的取整系数并不一样！（为什么呢？）
组成一个固定的量化矩阵。可以除以它的两倍（低质量图像），也可以只除以它的一半（高质量图像）
另外，因为是整数除法取模，所以量化是均匀的
也可以让量化不均匀：取一些不等距的点0，s1，s2，s3……
然后让0～s1都变到t1，s1～s2都变到t2……
Max-Lloyd最优量化器：给定各个灰度级的频率，要使得量化造成的均方误差最小
JPEG简单地假设频率分布是均匀的，但是其实肯定不是

其他的压缩算法：
JPEG：（有损）静态图像压缩
JPEG_LS：无损静态图像压缩（lossless）
没有映射了：直接在图像域上做文章；可以有量化
认为像素点之间是有先后顺序的，从左到右、从上到下
设置一个predictor，根据左边（A）、上边（B）、左上（C）、右上（D）四个已有的像素，预测当前像素
这个预测会基于一些判断，比如附近是不是图像边缘？
为什么不使用更多的之前值作为特征进行预测？为了节省内存

这是一个流水线作业，见图
1）有一个减法单元，能看到input（当前真实值f）和predictor的预测值（当前预测值f^）
它记录下两者之间的误差（e = f-f^）
2）quantizer将e量化（e' = e的量化）
输出到symbol encoder的是e'。
当预测比较准的时候，e是比较集中的：小的值多，大的值少。e'则更集中
对误差矩阵使用haffman编码，比起对于原图，更加节省空间！
3）有一个加法单元，能看到e'和predictor之前预测值f^
将其相加得到之前真实值的量化（e'+f^ = f'，即f的量化）
4）predictor得到之前真实值的量化f'，预测出当前真实值的量化f'，输出到2）

于是得到一个误差矩阵

5）symbol decoder解码得到e'
6）有一个加法单元，能看到e'和predictor之前预测值f^
将其相加得到之前真实值的量化（e'+f^ = f'，即f的量化）
将f'输出作为结果，同时也将f'输入到predictor

如果没有量化，e=e'，f=f'，就是无损的
注意，编码器跟解码器是对称的，编码器只能获得解码器拥有的信息。系统是对称的

MPEG：动态图像压缩压缩。这会用到mapper
是利用之前几帧来预测当前的帧
在这几帧之间，匹配相似的区域进行对比
同样只将误差编码

—————————————————————————————————————————————

作业题
A B C D
 3/8, 1/8, 1/8, and 3/8
A D B C
3 3 1 1
A D B+C
3 3 2
D+(B+C) A
5       3
(D+(B+C))+A
	X
	/\
	X	A
	/\
	D X
		/\
		B C

将图像分成不重叠的8x8块。
	matlab有简便的分块方法和逐块处理方法。

计算每个块的DCT（离散余弦变换）。这是在流行的软件包中实现的，例如Matlab。
量化每个块。您可以使用视频中的表格执行此操作，或者只需将每个系数除以N，将结果四舍五入到最接近的整数，然后再乘以N.尝试使用不同的N值。
您还可以尝试保留8个最大系数（总共8x8 = 64），并简单地将它们舍入为最接近的整数。
在反-量化和DCT之后可视化结果。
重复上述步骤，但不使用DCT，而是使用FFT（快速傅立叶变换）。
重复上述JPEG类型的压缩但不使用任何变换，只需对原始图像执行量化。
	于是颜色深一块浅一块很明显

现在为JPEG彩色图像做JPEG。
在Matlab中，使用rgb2ycbcr命令将Red-Green-Blue图像转换为Lumina和Chroma图像;然后独立地在三个通道中的每一个上执行JPEG样式的压缩。反-压缩后，反-颜色变换并显示结果。
	见.m代码文件。

在保持Y通道的压缩比恒定的同时，增加两个色度通道的压缩并观察结果。
	见.fig文件。

关于无损压缩
计算给定图像的直方图及其预测误差。如果
正在处理的像素位于坐标（0,0）处，考虑：
	基于（-1,0）处的像素进行预测;
	仅基于（0,1）处的像素进行预测;
	基于（-1,0），（-1,1）和（0,1）处的像素的平均值进行预测。
计算上一练习中每个预测变量的熵。哪个预测器会更好地压缩？
	
	首先写了一个求图像的熵的函数get_entropy

rgb=imread('lena.png');
rgb=imresize(rgb,[8,8],'bilinear'); % 尝试将其8*8化
I=rgb2gray(rgb);
[H,W] = size(I);
I1 = zeros(H,W);
I1(1,:) = I(1,:);
I1(2:H,:) = I(1:H-1,:);
I2 = zeros(H,W);
I2(:,1) = I(:,1);
I2(:,2:W) = I(:,1:W-1);
I3 = zeros(H,W);
I3(1,:) = I(1,:);
I3(:,1) = I(:,1);
I3(2:H,2:W) = I(1:H-1,1:W-1);
I4 = (I1+I2+I3)/3;
I = int16(I);
I1 = int16(I1);
I2 = int16(I2);
I4 = int16(I4);
get_entropy(I1-I) % 这里说的应该是误差的熵吧？
get_entropy(I2-I)
get_entropy(I4-I)

>>
ans =

    4.9589


ans =

    5.3237


ans =

    5.2653

按直觉来说，第三个值应该最小的
我觉得问题在于第一行/列的复制造成了不公平，它们不应该被计入熵的计算？？？
那如果不8*8化呢？

>>
ans =

    4.6597


ans =

    5.0462


ans =

    4.7807