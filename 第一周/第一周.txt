0、以后会讨论到图像和视频压缩算法

不同于计算机视觉（CV），从模型合成图像
DIP是获得图像，然后进行分析和处理
图像处理的应用范围很广
1、火星图片的图像增强
2、电路板、医学影像的自动识别和检测
3、好莱坞特效
4、视频识别，辨识不同的人是否在做相同的动作

光的频率分布是很广的，而人的可视频率范围是很窄的
可以使用多种不同的方式来拍摄同一个对象
Gamma、X-ray、Optical、Radio……它们能获取到不同的信息。

首先，我们需要了解我们的视觉系统

互补的两种视觉细胞
1、视杆体 数量多 感光不感颜色
	长于图像的轮廓 适用于低照度
2、视锥体 数量少 主要集中在黑色的中央凹部分 感颜色 少感光 但是感光的范围很大
	主要长于图像中的细节 适用于高照度
3、眼睛里有一个点没有传感细胞 称为盲点 但是我们往往感觉不到这个点的存在
	对它的研究让我们知道，如何在图像中生成和擦除东西！！！
视杆体和视锥体对于照度是互补的，但是不能同时作用
	因此 当场景的光照度改变 人需要时间适应

人的感受的韦伯定律：感知明显的区别的大小ΔI = 原始的刺激值I * 恒定比例
	不少东西都是如此：光照 重量 听觉 乃至社会意义上的工资
	如果I1是I2的两倍，那么ΔI1要达到ΔI2的两倍，才有同样的感知效果
	但是，当I1和I2的差别过于大，数量级都不同时，情况又不一样了：
	log(ΔI/I) 跟 logI 成负相关
	所以，若原来的光线很暗时，恒定比例很大：相同倍率的变化更难被感知到
	原来的光线很亮时，恒定比例很小：相同倍率的变化更容易被感知到
	两个东西如果都比较黑，那么要辨别出不同，需要它们具备更大倍率的差别
	可以通过处理，扩大这种不同，让肉眼都可以区别。

视觉错觉和灰度级的概念
	1、更暗色块和更亮色块的边界，如从左边看过去，会认为边界处比暗色块更深
	如从右边看过去，会认为边界处比亮色块更浅
	2、用浅色作衬，同样的东西会被认为更深
	
计算机采集和表示图像的方法：传感器阵列。
	无论采样再密集、量化层级再精细，空间域和值域都是离散的
	灰度级太少的话，图像明显变得不平滑了：出现了一层一层的梯田一样的“伪轮廓”
	cfa（滤色阵列）每一个像素点只能感受到红绿蓝中的一色光
	然后再用相邻的几个像素（可以是2x2或3x3，其中有红有绿有蓝）插值计算出中间一个像素的色彩
	也就是说，每个颜色的阵列/矩阵都是不完全的
表示视频则是用多幅图像/帧

四邻域、八领域的概念
让一个像素取它邻域的平均，如果发现跟某个邻点之间差距过大时，计算时可以抛弃掉该邻点
旋转、仿射变换等概念

傅立叶变换和离散余弦变换（discrete cosine transform）
离散余弦变换相当于一个长度大概是它两倍的离散傅里叶变换，但是只使用实数。

图像的加减乘除交并的概念
去除加性噪声的最简单方法：连拍多张，取平均

——————————————————————————————————————

作业：
量化
im = imread('lena.png');
newIm = round(im/64) * 64;
imshow(newIm);
二值化
im = imread('a.jpg');    %读取到一张图片   
thresh = graythresh(im); %自动确定二值化阈值
I2 = im2bw(im,thresh);   %对图像二值化
旋转
im = imread('lena.png');
newIm = imrotate(im,35,'bilinear');
imshow(newIm);
仿射
xform = [cos(pi/6),-sin(pi/6),0; sin(pi/6),cos(pi/6),0; 0,0,1];
im = imread('lena.png');
myT = maketform('affine', xform);
[newIm xdata ydata] = imtransform(im, myT);
imshow(newIm);
均值滤波
im = imread('lena.png');
w = fspecial('average',[5 5]);
newIm = imfilter(im,w,'replicate');
imshow(newIm);